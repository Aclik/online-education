# 1、定义组件名称 
a1.sources = r1
a1.channels = c1
a1.sinks = k1

# 2、配置Source
a1.sources.r1.type = org.apache.flume.source.kafka.KafkaSource
a1.sources.r1.batchSize = 5000
a1.sources.r1.batchDurationMillis = 2000
a1.sources.r1.kafka.bootstrap.servers = hadoop103:9092,hadoop104:9092,hadoop105:9092
a1.sources.r1.kafka.topics=online-education-topic

# 3、配置Channel
a1.channels.c1.type = file
a1.channels.c1.checkpointDir = /opt/project/online-education/flume/channel/checkpoint
a1.channels.c1.dataDirs = /opt/project/online-education/flume/channel/data
a1.channels.c1.maxFileSize = 2146435071
a1.channels.c1.capacity = 1000000
a1.channels.c1.keep-alive = 6

# 4、配置Sink
#	4.1) 配置Sink的类型
a1.sinks.k1.type = hdfs
#	4.2) 配置数据保存的目录
a1.sinks.k1.hdfs.path = hdfs://hadoop103:9000/project/online-education/data/%Y%m%d
#	4.3) 配置输出的文件类型
a1.sinks.k1.hdfs.fileType=DataStream 
#	4.4) 配置输出的Format类型
a1.sinks.k1.hdfs.writeFormat=TEXT
#	4.4) 配置保存文件的前缀
a1.sinks.k1.hdfs.filePrefix = flume.%Y%m%d%H%M
#	4.5) 配置是否启动满足某个条件进行滚动文件
a1.sinks.k1.hdfs.round = true
#	4.6) 滚动条件,每60(公司用600秒)秒滚动一个文件
a1.sinks.k1.hdfs.rollInterval=60
#	4.7) 滚动条件,每128M滚动一个文件
a1.sinks.k1.hdfs.rollSize=134217728
a1.sinks.k1.hdfs.rollCount=0
#	4.8) 滚动条件,每次拉取1000个event写入HDFS
a1.sinks.k1.hdfs.batchsize=1000
#	4.9) 打开、写的线程池数
a1.sinks.k1.hdfs.threadsPoolSize=1
#	4.10) 监控文件超时时长
a1.sinks.k1.hdfs.idelTimeout=600
# 	4.11) 
a1.sinks.k1.hdfs.roundValue = 10
a1.sinks.k1.hdfs.roundUnit = minute

# 5、绑定Source和Channel
a1.sources.r1.channels = c1
a1.sinks.k1.channel =c1